{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataPrepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:10:33.698855Z",
     "start_time": "2023-11-21T12:10:33.694420Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/tmp-data/zhx/DriverOrderOfflineRL/tianshou')\n",
    "sys.path.append('/tmp-data/zhx/DriverOrderOfflineRL/gym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:10:36.697812Z",
     "start_time": "2023-11-21T12:10:36.693976Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import *\n",
    "from pprint import pprint\n",
    "import os\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:07:49.567303Z",
     "start_time": "2023-11-21T12:06:33.393844Z"
    }
   },
   "outputs": [],
   "source": [
    "buffer_data = pd.read_csv('/tmp-data/yanhaoyue/workspace/RL/data/support_feature_buffer.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:10:45.922685Z",
     "start_time": "2023-11-21T12:10:39.411499Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque, namedtuple\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import wandb\n",
    "import argparse\n",
    "import glob\n",
    "import random\n",
    "from types import SimpleNamespace\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bufferClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:10:49.297614Z",
     "start_time": "2023-11-21T12:10:49.219167Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size, batch_size, device):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "\n",
    "    def add_batch(self, states, actions, rewards, next_states, dones):\n",
    "        \"\"\"Add a batch of experiences to memory.\"\"\"\n",
    "        for i in range(len(states)):\n",
    "            self.add(states[i], actions[i], rewards[i], next_states[i], dones[i])\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.stack([e.state for e in experiences if e is not None])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.stack([e.next_state for e in experiences if e is not None])).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "    \n",
    "    def create_dataloader(self):\n",
    "        \"\"\"Create a DataLoader from the replay buffer.\"\"\"\n",
    "        states = torch.tensor([e.state for e in self.memory], dtype=torch.float32, device=self.device)\n",
    "        actions = torch.tensor([e.action for e in self.memory], dtype=torch.long, device=self.device)\n",
    "        rewards = torch.tensor([e.reward for e in self.memory], dtype=torch.float32, device=self.device)\n",
    "        next_states = torch.tensor([e.next_state for e in self.memory], dtype=torch.float32, device=self.device)\n",
    "        dones = torch.tensor([e.done for e in self.memory], dtype=torch.long, device=self.device)\n",
    "\n",
    "        dataset = TensorDataset(states, actions.unsqueeze(1), rewards.unsqueeze(1), next_states, dones.unsqueeze(1))\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:10:51.726358Z",
     "start_time": "2023-11-21T12:10:51.717597Z"
    }
   },
   "outputs": [],
   "source": [
    "def save(args, save_name, model, wandb, ep=None):\n",
    "    import os\n",
    "    save_dir = current_dir + '/trained_models/' + args.run_name + '/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    if not ep == None:\n",
    "        torch.save(model.state_dict(), save_dir + args.run_name + save_name + str(ep) + \".pth\")\n",
    "        wandb.save(save_dir + save_name + str(ep) + \".pth\")\n",
    "    else:\n",
    "        torch.save(model.state_dict(), save_dir + args.run_name + save_name + \".pth\")\n",
    "        wandb.save(save_dir + save_name + \".pth\")\n",
    "\n",
    "def collect_data(dataset, buffer_source):\n",
    "    s, a, r, s_, d = buffer_source\n",
    "    dataset.add(s, a, r, s_, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:12:11.837616Z",
     "start_time": "2023-11-21T12:12:11.831762Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/tmp-data/yanhaoyue/workspace/RL/CQL/CQL-DQN')\n",
    "from agent import CQLAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:12:40.296890Z",
     "start_time": "2023-11-21T12:12:40.284621Z"
    }
   },
   "outputs": [],
   "source": [
    "# config\n",
    "parser = argparse.ArgumentParser(description='RL')\n",
    "parser.add_argument(\"--run_name\", type=str, default=\"CQL-DDQN\", help=\"Run name, default: CQL-DQN\")\n",
    "parser.add_argument(\"--env\", type=str, default=\"order_filter\", help=\"env name\")\n",
    "parser.add_argument(\"--episodes\", type=int, default=10000, help=\"Number of episodes, default: 200\")\n",
    "parser.add_argument(\"--buffer_size\", type=int, default=1_000_000, help=\"Maximal training dataset size, default: 100_000\")\n",
    "parser.add_argument(\"--seed\", type=int, default=1, help=\"Seed, default: 1\")\n",
    "parser.add_argument(\"--min_eps\", type=float, default=0.01, help=\"Minimal Epsilon, default: 4\")\n",
    "parser.add_argument(\"--eps_frames\", type=int, default=1e4, help=\"Number of steps for annealing the epsilon value to the min epsilon, default: 1e5\")\n",
    "parser.add_argument(\"--log_video\", type=int, default=0, help=\"Log agent behaviour to wanbd when set to 1, default: 0\")\n",
    "parser.add_argument(\"--save_every\", type=int, default=100, help=\"Saves the network every x epochs, default: 25\")\n",
    "\n",
    "config = SimpleNamespace()\n",
    "# args = parser.parse_args()\n",
    "config.run_name = \"11-22-CQL-DDQN_train\"\n",
    "config.env = 'order_filter'\n",
    "config.episodes = 10000\n",
    "config.buffer_size = 1_000_000\n",
    "config.seed = 1\n",
    "config.min_eps = 1e-4\n",
    "config.eps_frames = 1e4\n",
    "config.log_video = 0\n",
    "config.save_every = 1\n",
    "config.eval_every = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:12:50.949840Z",
     "start_time": "2023-11-21T12:12:50.939909Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "\n",
    "batches = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "eps = 1.\n",
    "d_eps = 1 - config.min_eps\n",
    "steps = 0\n",
    "average10 = deque(maxlen=10)\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:12:53.935571Z",
     "start_time": "2023-11-21T12:12:53.925594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state size\n",
    "buffer_s_list = eval(buffer_data['s'].iloc[0])\n",
    "len(buffer_s_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:12:56.192075Z",
     "start_time": "2023-11-21T12:12:56.112710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a\n",
       "5.0    234962\n",
       "4.0    179231\n",
       "3.0    124849\n",
       "2.0    111761\n",
       "0.0     93309\n",
       "1.0     93183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# action size\n",
    "buffer_data['a'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:13:01.100896Z",
     "start_time": "2023-11-21T12:13:00.565782Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = CQLAgent(state_size=11,\n",
    "                    action_size=6,\n",
    "                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:13:03.344224Z",
     "start_time": "2023-11-21T12:13:03.338543Z"
    }
   },
   "outputs": [],
   "source": [
    "buffer = ReplayBuffer(buffer_size=config.buffer_size, batch_size=32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:28:08.942476Z",
     "start_time": "2023-11-21T12:13:04.894252Z"
    }
   },
   "outputs": [],
   "source": [
    "s = buffer_data['s'].apply(ast.literal_eval).values\n",
    "a = buffer_data['a'].values\n",
    "r = buffer_data['r'].values\n",
    "s_ = buffer_data['s_'].apply(ast.literal_eval).values\n",
    "d = buffer_data['d'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:35:31.561563Z",
     "start_time": "2023-11-21T12:35:14.166535Z"
    }
   },
   "outputs": [],
   "source": [
    "buffer.add_batch(s, a, r, s_, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:35:58.272784Z",
     "start_time": "2023-11-21T12:35:31.613107Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2289787/1897141590.py:42: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  actions = torch.tensor([e.action for e in self.memory], dtype=torch.long, device=self.device)\n",
      "/tmp/ipykernel_2289787/1897141590.py:45: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  dones = torch.tensor([e.done for e in self.memory], dtype=torch.long, device=self.device)\n"
     ]
    }
   ],
   "source": [
    "dataloader = buffer.create_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:35:58.315816Z",
     "start_time": "2023-11-21T12:35:58.304142Z"
    }
   },
   "outputs": [],
   "source": [
    "states, actions, rewards, next_states, dones = buffer.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:35:58.351349Z",
     "start_time": "2023-11-21T12:35:58.345672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape # torch.Size([32, 11])\n",
    "actions.shape # torch.Size([32, 11])\n",
    "rewards.shape # torch.Size([32, 11])\n",
    "dones.shape # torch.Size([32, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:35:58.398084Z",
     "start_time": "2023-11-21T12:35:58.393212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(run_name='11-21-CQL-DDQN_train',\n",
      "          env='order_filter',\n",
      "          episodes=10000,\n",
      "          buffer_size=1000000,\n",
      "          seed=1,\n",
      "          min_eps=0.0001,\n",
      "          eps_frames=10000.0,\n",
      "          log_video=0,\n",
      "          save_every=1,\n",
      "          eval_every=100)\n"
     ]
    }
   ],
   "source": [
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:36:13.139542Z",
     "start_time": "2023-11-21T12:35:58.425997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhongxi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp-data/zhx/DriverOrderOfflineRL/scripts/wandb/run-20231121_123601-id3q780s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hongxi/CQL-DDQN/runs/id3q780s' target=\"_blank\">11-21-CQL-DDQN_train</a></strong> to <a href='https://wandb.ai/hongxi/CQL-DDQN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hongxi/CQL-DDQN' target=\"_blank\">https://wandb.ai/hongxi/CQL-DDQN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hongxi/CQL-DDQN/runs/id3q780s' target=\"_blank\">https://wandb.ai/hongxi/CQL-DDQN/runs/id3q780s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2289787/225390909.py\", line 13, in <module>\n",
      "    loss, cql_loss, bellmann_error = agent.learn((states, actions, rewards, next_states, dones))\n",
      "  File \"/tmp-data/yanhaoyue/workspace/RL/CQL/CQL-DQN/agent.py\", line 54, in learn\n",
      "    Q_targets_next = self.target_net(next_states).detach().max(1)[0].unsqueeze(1)\n",
      "  File \"/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp-data/yanhaoyue/workspace/RL/CQL/CQL-DQN/networks.py\", line 17, in forward\n",
      "    x = torch.relu(self.head_1(input))\n",
      "  File \"/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x109 and 11x256)\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">11-21-CQL-DDQN_train</strong> at: <a href='https://wandb.ai/hongxi/CQL-DDQN/runs/id3q780s' target=\"_blank\">https://wandb.ai/hongxi/CQL-DDQN/runs/id3q780s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231121_123601-id3q780s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x109 and 11x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m next_states \u001b[38;5;241m=\u001b[39m next_states\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m dones \u001b[38;5;241m=\u001b[39m dones\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m loss, cql_loss, bellmann_error \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdones\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batches \u001b[38;5;241m%\u001b[39m config\u001b[38;5;241m.\u001b[39meval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/tmp-data/yanhaoyue/workspace/RL/CQL/CQL-DQN/agent.py:54\u001b[0m, in \u001b[0;36mCQLAgent.learn\u001b[0;34m(self, experiences)\u001b[0m\n\u001b[1;32m     52\u001b[0m states, actions, rewards, next_states, dones \u001b[38;5;241m=\u001b[39m experiences\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 54\u001b[0m     Q_targets_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m     Q_targets \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m Q_targets_next \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones))\n\u001b[1;32m     57\u001b[0m Q_a_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork(states)\n",
      "File \u001b[0;32m/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tmp-data/yanhaoyue/workspace/RL/CQL/CQL-DQN/networks.py:17\u001b[0m, in \u001b[0;36mDDQN.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_1(x))\n\u001b[1;32m     19\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_2(x)\n",
      "File \u001b[0;32m/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x109 and 11x256)"
     ]
    }
   ],
   "source": [
    "with wandb.init(project=\"CQL-DDQN\", name=config.run_name, config=config, dir=current_dir):\n",
    "    wandb.watch(agent.network, log=\"gradients\", log_freq=10)\n",
    "\n",
    "    for i in range(1, config.episodes+1):\n",
    "\n",
    "        for batch_idx, experience in enumerate(dataloader):\n",
    "            states, actions, rewards, next_states, dones = experience\n",
    "            states = states.to(device)\n",
    "            actions = actions.to(device)\n",
    "            rewards = rewards.to(device)\n",
    "            next_states = next_states.to(device)\n",
    "            dones = dones.to(device)\n",
    "            loss, cql_loss, bellmann_error = agent.learn((states, actions, rewards, next_states, dones))\n",
    "            batches += 1\n",
    "\n",
    "            if batches % config.eval_every == 0:\n",
    "\n",
    "                wandb.log({\n",
    "                           \"Q Loss\": loss,\n",
    "                           \"CQL Loss\": cql_loss,\n",
    "                           \"Bellmann error\": bellmann_error,\n",
    "                           \"Episode\": i,\n",
    "                           \"Batches\": batches})\n",
    "\n",
    "        if (i %10 == 0) and config.log_video:\n",
    "            mp4list = glob.glob('video/*.mp4')\n",
    "            if len(mp4list) > 1:\n",
    "                mp4 = mp4list[-2]\n",
    "                wandb.log({\"gameplays\": wandb.Video(mp4, caption='episode: '+str(i-10), fps=4, format=\"gif\"), \"Episode\": i})\n",
    "\n",
    "        if i % config.save_every == 0:\n",
    "            save(config, save_name='', model=agent.network, wandb=wandb, ep=i)\n",
    "            print(\"Episode: \", i, \"Batches: \", batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_test",
   "language": "python",
   "name": "rl_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
