{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/zhx/word/work/DriverOrderOfflineRL/rl-exploration-baselines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "@Project ：rl-exploration-baselines \n",
    "@File ：inverse_forward_networks.py\n",
    "@Author ：YUAN Mingqi\n",
    "@Date ：2022/9/20 14:07 \n",
    "'''\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "\n",
    "class InverseForwardDynamicsModel(nn.Module):\n",
    "    def __init__(self, kwargs):\n",
    "        super(InverseForwardDynamicsModel, self).__init__()\n",
    "\n",
    "        self.inverse_model = nn.Sequential(\n",
    "            nn.Linear(kwargs['latent_dim'] * 2, 64), nn.LeakyReLU(),\n",
    "            nn.Linear(64, kwargs['action_dim'])\n",
    "        )\n",
    "\n",
    "        self.forward_model = nn.Sequential(\n",
    "            nn.Linear(kwargs['latent_dim'] + kwargs['action_dim'], 64), nn.LeakyReLU(),\n",
    "            nn.Linear(64, kwargs['latent_dim'])\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, obs, action, next_obs, training=True):\n",
    "        if training:\n",
    "            # inverse prediction\n",
    "            im_input_tensor = torch.cat([obs, next_obs], dim=1)\n",
    "            pred_action = self.inverse_model(im_input_tensor)\n",
    "            # forward prediction\n",
    "            fm_input_tensor = torch.cat([obs, action], dim=-1)\n",
    "            pred_next_obs = self.forward_model(fm_input_tensor)\n",
    "\n",
    "            return pred_action, pred_next_obs\n",
    "        else:\n",
    "            # forward prediction\n",
    "            fm_input_tensor = torch.cat([obs, action], dim=-1)\n",
    "            pred_next_obs = self.forward_model(fm_input_tensor)\n",
    "\n",
    "            return pred_next_obs\n",
    "\n",
    "class MlpEncoder(nn.Module):\n",
    "    def __init__(self, obs_shape, latent_dim):\n",
    "        super(MlpEncoder, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(obs_shape[0], 64), nn.ReLU(),\n",
    "            nn.Linear(64, 64), nn.ReLU(),\n",
    "            nn.Linear(64, latent_dim), nn.LayerNorm(latent_dim))\n",
    "\n",
    "    def forward(self, ob):\n",
    "        x = self.main(ob)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CnnEncoder(nn.Module):\n",
    "    def __init__(self, kwargs):\n",
    "        super(CnnEncoder, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(kwargs['in_channels'], 32, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(32), nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(32), nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(64), nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(64), nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, obs, next_obs=None):\n",
    "        if next_obs is not None:\n",
    "            input_tensor = torch.cat([obs, next_obs], dim=1)\n",
    "        else:\n",
    "            input_tensor = obs\n",
    "\n",
    "        latent_vectors = self.main(input_tensor)\n",
    "\n",
    "        return latent_vectors.view(latent_vectors.size(0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICM(object):\n",
    "    def __init__(self,\n",
    "                 envs,\n",
    "                 device,\n",
    "                 lr,\n",
    "                 batch_size,\n",
    "                 beta,\n",
    "                 kappa\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Curiosity-Driven Exploration by Self-Supervised Prediction\n",
    "        Paper: http://proceedings.mlr.press/v70/pathak17a/pathak17a.pdf\n",
    "\n",
    "        :param envs: The environment to learn from.\n",
    "        :param device: Device (cpu, cuda, ...) on which the code should be run.\n",
    "        :param lr: The learning rate of inverse and forward dynamics model.\n",
    "        :param batch_size: The batch size to train the dynamics model.\n",
    "        :param beta: The initial weighting coefficient of the intrinsic rewards.\n",
    "        :param kappa: The decay rate.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if envs.action_space.__class__.__name__ == \"Discrete\":\n",
    "            self.ob_shape = envs.observation_space.shape\n",
    "            self.action_shape = envs.action_space.n\n",
    "            self.action_type = 'dis'\n",
    "            self.inverse_forward_model = InverseForwardDynamicsModel(\n",
    "                kwargs={'latent_dim': 1024, 'action_dim': self.action_shape}\n",
    "            ).to(device)\n",
    "            self.im_loss = nn.CrossEntropyLoss()\n",
    "        elif envs.action_space.__class__.__name__ == 'Box':\n",
    "            self.ob_shape = envs.observation_space.shape\n",
    "            self.action_shape = envs.action_space.shape\n",
    "            self.action_type = 'cont'\n",
    "            self.inverse_forward_model = InverseForwardDynamicsModel(\n",
    "                kwargs={'latent_dim': self.ob_shape[0], 'action_dim': self.action_shape[0]}\n",
    "            ).to(device)\n",
    "            self.im_loss = nn.MSELoss()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.fm_loss = nn.MSELoss()\n",
    "\n",
    "        if len(self.ob_shape) == 3:\n",
    "            self.cnn_encoder = CnnEncoder(kwargs={'in_channels': 4}).to(device)\n",
    "\n",
    "        self.optimizer = optim.Adam(lr=self.lr, params=self.inverse_forward_model.parameters())\n",
    "\n",
    "    def update(self, rollouts):\n",
    "        n_steps = rollouts['observations'].shape[0]\n",
    "        n_envs = rollouts['observations'].shape[1]\n",
    "        obs = torch.from_numpy(rollouts['observations']).reshape(n_steps * n_envs, *self.ob_shape)\n",
    "        if self.action_type == 'dis':\n",
    "            actions = torch.from_numpy(rollouts['actions']).reshape(n_steps * n_envs, )\n",
    "            actions = F.one_hot(actions.to(torch.int64), self.action_shape).float()\n",
    "        else:\n",
    "            actions = torch.from_numpy(rollouts['actions']).reshape(n_steps * n_envs, self.action_shape[0])\n",
    "        obs = obs.to(self.device)\n",
    "        actions = actions.to(self.device)\n",
    "\n",
    "        if len(self.ob_shape) == 3:\n",
    "            encoded_obs = self.cnn_encoder(obs)\n",
    "        else:\n",
    "            encoded_obs = obs\n",
    "\n",
    "        dataset = TensorDataset(encoded_obs[:-1], actions[:-1], encoded_obs[1:])\n",
    "        loader = DataLoader(dataset=dataset, batch_size=self.batch_size, drop_last=True)\n",
    "\n",
    "        for idx, batch_data in enumerate(loader):\n",
    "            batch_obs = batch_data[0]\n",
    "            batch_actions = batch_data[1]\n",
    "            batch_next_obs = batch_data[2]\n",
    "\n",
    "            pred_actions, pred_next_obs = self.inverse_forward_model(\n",
    "                batch_obs, batch_actions, batch_next_obs\n",
    "            )\n",
    "\n",
    "            loss = self.im_loss(pred_actions, batch_actions) + \\\n",
    "                   self.fm_loss(pred_next_obs, batch_next_obs)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def compute_irs(self, rollouts, time_steps):\n",
    "        \"\"\"\n",
    "        Compute the intrinsic rewards using the collected observations.\n",
    "        :param rollouts: The collected experiences.\n",
    "        :param time_steps: The current time steps.\n",
    "        :return: The intrinsic rewards\n",
    "        \"\"\"\n",
    "\n",
    "        # compute the weighting coefficient of timestep t\n",
    "        beta_t = self.beta * np.power(1. - self.kappa, time_steps)\n",
    "        n_steps = rollouts['observations'].shape[0]\n",
    "        n_envs = rollouts['observations'].shape[1]\n",
    "        intrinsic_rewards = np.zeros(shape=(n_steps, n_envs, 1))\n",
    "\n",
    "        obs = torch.from_numpy(rollouts['observations'])\n",
    "        actions = torch.from_numpy(rollouts['actions'])\n",
    "        if self.action_type == 'dis':\n",
    "            # actions size: (n_steps, n_envs, 1)\n",
    "            actions = F.one_hot(actions[:, :, 0].to(torch.int64), self.action_shape).float()\n",
    "        obs = obs.to(self.device)\n",
    "        actions = actions.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx in range(n_envs):\n",
    "                if len(self.ob_shape) == 3:\n",
    "                    encoded_obs = self.cnn_encoder(obs[:, idx, :, :, :])\n",
    "                else:\n",
    "                    encoded_obs = obs[:, idx]\n",
    "                pred_next_obs = self.inverse_forward_model(\n",
    "                    encoded_obs[:-1], actions[:-1, idx], next_obs=None, training=False)\n",
    "                processed_next_obs = torch.clip(encoded_obs[1:], min=-1.0, max=1.0)\n",
    "                processed_pred_next_obs = torch.clip(pred_next_obs, min=-1.0, max=1.0)\n",
    "\n",
    "                intrinsic_rewards[:-1, idx] = F.mse_loss(processed_pred_next_obs, processed_next_obs, reduction='mean').cpu().numpy()\n",
    "            # processed_next_obs = process(encoded_obs[1:n_steps], normalize=True, range=(-1, 1))\n",
    "            # processed_pred_next_obs = process(pred_next_obs, normalize=True, range=(-1, 1))\n",
    "        # train the icm\n",
    "        self.update(rollouts)\n",
    "\n",
    "        return beta_t * intrinsic_rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='RL')\n",
    "    parser.add_argument('--action-space', type=str, default='cont')\n",
    "    parser.add_argument('--algo', type=str, default='ppo')\n",
    "    parser.add_argument('--exploration', type=str, default='')\n",
    "    parser.add_argument('--env-id', type=str, default='CartPole-v1')\n",
    "    parser.add_argument('--total-time-steps', type=int, default=10000000)\n",
    "    parser.add_argument('--n-envs', type=int, default=10)\n",
    "    parser.add_argument('--n-steps', type=int, default=128)\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = int(args.total_time_steps / args.n_steps / args.n_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhx/.conda/envs/academy/lib/python3.8/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/zhx/.conda/envs/academy/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(args.env_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re3 = ICM(envs=env, device=device, lr=0.0003, batch_size=64, beta=1e-2, kappa=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academy",
   "language": "python",
   "name": "academy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
