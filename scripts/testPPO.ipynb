{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e73883c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:11:16.428707Z",
     "start_time": "2023-11-23T11:11:16.424527Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/zhx/word/DriverOrderOfflineRL/cage-challenge-1/CybORG')\n",
    "sys.path.append('/home/zhx/word/DriverOrderOfflineRL/tianshou')\n",
    "sys.path.append('/home/zhx/word/DriverOrderOfflineRL/tianshou/examples/atari')\n",
    "sys.path.append('/home/zhx/word/DriverOrderOfflineRL/gym')\n",
    "sys.path.append('/home/zhx/word/DriverOrderOfflineRL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078790e6",
   "metadata": {},
   "source": [
    "### args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1d7754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:20:23.005018Z",
     "start_time": "2023-11-23T11:20:22.999120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhx/miniconda3/envs/tianshou/lib/python3.11/site-packages/wandb/sdk/launch/builder/build.py:11: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch import nn\n",
    "\n",
    "from tianshou.data import Collector, VectorReplayBuffer\n",
    "from tianshou.policy import PPOPolicy\n",
    "from tianshou.policy.modelbased.icm import ICMPolicy\n",
    "from tianshou.trainer import onpolicy_trainer\n",
    "from tianshou.utils import TensorboardLogger, WandbLogger\n",
    "from tianshou.utils.net.discrete import IntrinsicCuriosityModule\n",
    "from tianshou.env import SubprocVectorEnv, DummyVectorEnv\n",
    "from tianshou.utils.net.common import ActorCritic\n",
    "from tianshou.utils.net.discrete import Actor, Critic, IntrinsicCuriosityModule\n",
    "\n",
    "from typing import Any, Dict, Optional, Sequence, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c283577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:16:48.021696Z",
     "start_time": "2023-11-23T11:16:48.004972Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--task\", type=str, default=\"cyborg\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=0)\n",
    "    parser.add_argument(\"--scale-obs\", type=int, default=0)\n",
    "    parser.add_argument(\"--eps-test\", type=float, default=0.05)\n",
    "    parser.add_argument(\"--eps-train\", type=float, default=1.)\n",
    "    parser.add_argument(\"--eps-train-final\", type=float, default=0.05)\n",
    "    parser.add_argument(\"--buffer-size\", type=int, default=500000)\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.0001)\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99)\n",
    "    parser.add_argument(\"--n-step\", type=int, default=1)\n",
    "    parser.add_argument(\"--target-update-freq\", type=int, default=1000)\n",
    "    parser.add_argument(\"--epoch\", type=int, default=2000)\n",
    "    parser.add_argument(\"--step-per-epoch\", type=int, default=10)\n",
    "    parser.add_argument(\"--step-per-collect\", type=int, default=100)\n",
    "    parser.add_argument(\"--repeat-per-collect\", type=int, default=1)\n",
    "    parser.add_argument(\"--update-per-step\", type=float, default=1)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=32)\n",
    "    parser.add_argument(\"--rew-norm\", type=int, default=False)\n",
    "    parser.add_argument(\"--hidden-size\", type=int, default=512)\n",
    "    parser.add_argument(\"--vf-coef\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--ent-coef\", type=float, default=0.01)\n",
    "    parser.add_argument(\"--gae-lambda\", type=float, default=0.95)\n",
    "    parser.add_argument(\"--lr-decay\", type=int, default=True)\n",
    "    parser.add_argument(\"--training-num\", type=int, default=10)\n",
    "    parser.add_argument(\"--test-num\", type=int, default=10)\n",
    "    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--eps-clip\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--dual-clip\", type=float, default=None)\n",
    "    parser.add_argument(\"--value-clip\", type=int, default=0)\n",
    "    parser.add_argument(\"--norm-adv\", type=int, default=1)\n",
    "    parser.add_argument(\"--recompute-adv\", type=int, default=0)\n",
    "    parser.add_argument(\"--logdir\", type=str, default=\"log\")\n",
    "    parser.add_argument(\"--render\", type=float, default=0.)\n",
    "    parser.add_argument(\n",
    "        \"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    parser.add_argument(\"--frames-stack\", type=int, default=1)\n",
    "    parser.add_argument(\"--resume-path\", type=str, default=None)\n",
    "    parser.add_argument(\"--resume-id\", type=str, default=None)\n",
    "    parser.add_argument(\n",
    "        \"--logger\",\n",
    "        type=str,\n",
    "        default=\"wandb\",\n",
    "        choices=[\"tensorboard\", \"wandb\"],\n",
    "    )\n",
    "    parser.add_argument(\"--wandb-project\", type=str, default=\"cyborg.ppo\")\n",
    "    parser.add_argument(\n",
    "        \"--watch\",\n",
    "        default=False,\n",
    "        action=\"store_true\",\n",
    "        help=\"watch the play of pre-trained policy only\"\n",
    "    )\n",
    "    parser.add_argument(\"--save-buffer-name\", type=str, default=None)\n",
    "    parser.add_argument(\n",
    "        \"--icm-lr-scale\",\n",
    "        type=float,\n",
    "        default=0.,\n",
    "        help=\"use intrinsic curiosity module with this lr scale\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--icm-reward-scale\",\n",
    "        type=float,\n",
    "        default=0.01,\n",
    "        help=\"scaling factor for intrinsic curiosity reward\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--icm-forward-loss-weight\",\n",
    "        type=float,\n",
    "        default=0.2,\n",
    "        help=\"weight for the forward model loss in ICM\"\n",
    "    )\n",
    "    return parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3a6571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:16:59.758734Z",
     "start_time": "2023-11-23T11:16:59.716664Z"
    }
   },
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d71967",
   "metadata": {},
   "source": [
    "### env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2b5860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:18:28.770871Z",
     "start_time": "2023-11-23T11:18:27.690549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations shape: (52,)\n",
      "Actions shape: 54\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from pprint import pprint\n",
    "from CybORG import CybORG\n",
    "from CybORG.Shared.Actions import *\n",
    "from CybORG.Agents import RedMeanderAgent, B_lineAgent\n",
    "from CybORG.Agents.Wrappers import *\n",
    "\n",
    "path = str(inspect.getfile(CybORG))\n",
    "path = path[:-10] + '/Shared/Scenarios/Scenario1b.yaml'\n",
    "\n",
    "# seed\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# env\n",
    "CYBORG = CybORG(path,'sim', agents={'Red': RedMeanderAgent})\n",
    "env = ChallengeWrapper(env=CYBORG, agent_name=\"Blue\", max_steps=args.step_per_epoch)\n",
    "train_envs = SubprocVectorEnv([lambda: ChallengeWrapper(env=CybORG(path,'sim', agents={'Red': RedMeanderAgent}), agent_name=\"Blue\", max_steps=args.step_per_epoch) for _ in range(1)])\n",
    "test_envs = SubprocVectorEnv([lambda: ChallengeWrapper(env=CybORG(path,'sim', agents={'Red': RedMeanderAgent}), agent_name=\"Blue\", max_steps=args.step_per_epoch) for _ in range(1)])\n",
    "\n",
    "args.state_shape = env.observation_space.shape or env.observation_space.n\n",
    "args.action_shape = env.action_space.shape or env.action_space.n\n",
    "print(\"Observations shape:\", args.state_shape)\n",
    "print(\"Actions shape:\", args.action_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de91238",
   "metadata": {},
   "source": [
    "### network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee187732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:42:37.083549Z",
     "start_time": "2023-11-23T11:42:37.076014Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"Reference: Human-level control through deep reinforcement learning.\n",
    "\n",
    "    For advanced usage (how to customize the network), please refer to\n",
    "    :ref:`build_the_network`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_shape: Sequence[int],\n",
    "        action_shape: Sequence[int],\n",
    "        device: Union[str, int, torch.device] = \"cpu\",\n",
    "        features_only: bool = False,\n",
    "        output_dim: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.output_dim = 512\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_shape, 512), nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 512), nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        obs: Union[np.ndarray, torch.Tensor],\n",
    "        state: Optional[Any] = None,\n",
    "        info: Dict[str, Any] = {},\n",
    "    ) -> Tuple[torch.Tensor, Any]:\n",
    "        r\"\"\"Mapping: s -> Q(s, \\*).\"\"\"\n",
    "        obs = torch.as_tensor(obs, device=self.device, dtype=torch.float32)\n",
    "        return self.net(obs), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce791adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T11:55:32.764245Z",
     "start_time": "2023-11-23T11:55:32.688944Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "net = DQN(args.state_shape[0], args.action_shape, args.device).to(args.device)\n",
    "actor = Actor(net, args.action_shape, softmax_output=False, device=args.device)\n",
    "critic = Critic(net, device=args.device)\n",
    "optim = torch.optim.Adam(ActorCritic(actor, critic).parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58186be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = None\n",
    "if args.lr_decay:\n",
    "    # decay learning rate to 0 linearly\n",
    "    max_update_num = np.ceil(\n",
    "        args.step_per_epoch / args.step_per_collect\n",
    "    ) * args.epoch\n",
    "\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optim, lr_lambda=lambda epoch: 1 - epoch / max_update_num\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e66b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define policy\n",
    "def dist(p):\n",
    "    return torch.distributions.Categorical(logits=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1027bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = PPOPolicy(\n",
    "    actor,\n",
    "    critic,\n",
    "    optim,\n",
    "    dist,\n",
    "    discount_factor=args.gamma,\n",
    "    gae_lambda=args.gae_lambda,\n",
    "    max_grad_norm=args.max_grad_norm,\n",
    "    vf_coef=args.vf_coef,\n",
    "    ent_coef=args.ent_coef,\n",
    "    reward_normalization=args.rew_norm,\n",
    "    action_scaling=False,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    action_space=env.action_space,\n",
    "    eps_clip=args.eps_clip,\n",
    "    value_clip=args.value_clip,\n",
    "    dual_clip=args.dual_clip,\n",
    "    advantage_normalization=args.norm_adv,\n",
    "    recompute_advantage=args.recompute_adv,\n",
    ").to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8087e4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /home/zhx/miniconda3/envs/tianshou/lib/python3.11/site-packages/wandb/sdk/wandb_init.py 848 getcaller\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb 单元格 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# logger\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mlogger \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwandb\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     logger \u001b[39m=\u001b[39m WandbLogger(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         save_interval\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         name\u001b[39m=\u001b[39;49mlog_name\u001b[39m.\u001b[39;49mreplace(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49msep, \u001b[39m\"\u001b[39;49m\u001b[39m__\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         run_id\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mresume_id,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         config\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         project\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mwandb_project,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(log_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22506368227d/home/zhx/word/DriverOrderOfflineRL/scripts/testPPO.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m writer\u001b[39m.\u001b[39madd_text(\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(args))\n",
      "File \u001b[0;32m~/word/DriverOrderOfflineRL/tianshou/tianshou/utils/logger/wandb.py:66\u001b[0m, in \u001b[0;36mWandbLogger.__init__\u001b[0;34m(self, train_interval, test_interval, update_interval, save_interval, write_flush, project, name, entity, run_id, config)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m project \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     project \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mWANDB_PROJECT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtianshou\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwandb_run \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39;49minit(\n\u001b[1;32m     67\u001b[0m     project\u001b[39m=\u001b[39;49mproject,\n\u001b[1;32m     68\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m     69\u001b[0m     \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49mrun_id,\n\u001b[1;32m     70\u001b[0m     resume\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     71\u001b[0m     entity\u001b[39m=\u001b[39;49mentity,\n\u001b[1;32m     72\u001b[0m     sync_tensorboard\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     73\u001b[0m     monitor_gym\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     74\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     75\u001b[0m ) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wandb\u001b[39m.\u001b[39mrun \u001b[39melse\u001b[39;00m wandb\u001b[39m.\u001b[39mrun\n\u001b[1;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwandb_run\u001b[39m.\u001b[39m_label(repo\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtianshou\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensorboard_logger: Optional[TensorboardLogger] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tianshou/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1189\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \u001b[39massert\u001b[39;00m logger\n\u001b[1;32m   1188\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39minterrupted\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39me)\n\u001b[0;32m-> 1189\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   1190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1191\u001b[0m     error_seen \u001b[39m=\u001b[39m e\n",
      "File \u001b[0;32m~/miniconda3/envs/tianshou/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1166\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1164\u001b[0m except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[1;32m   1165\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m     run \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39;49minit()\n\u001b[1;32m   1167\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[1;32m   1168\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/tianshou/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:752\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    749\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcommunicating run to backend with \u001b[39m\u001b[39m{\u001b[39;00mtimeout\u001b[39m}\u001b[39;00m\u001b[39m second timeout\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    751\u001b[0m run_init_handle \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39minterface\u001b[39m.\u001b[39mdeliver_run(run)\n\u001b[0;32m--> 752\u001b[0m result \u001b[39m=\u001b[39m run_init_handle\u001b[39m.\u001b[39;49mwait(\n\u001b[1;32m    753\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    754\u001b[0m     on_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_progress_init,\n\u001b[1;32m    755\u001b[0m     cancel\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    756\u001b[0m )\n\u001b[1;32m    757\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    758\u001b[0m     run_result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mrun_result\n",
      "File \u001b[0;32m~/miniconda3/envs/tianshou/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py:283\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interface\u001b[39m.\u001b[39m_transport_keepalive_failed():\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m MailboxError(\u001b[39m\"\u001b[39m\u001b[39mtransport failed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 283\u001b[0m found, abandoned \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slot\u001b[39m.\u001b[39;49m_get_and_clear(timeout\u001b[39m=\u001b[39;49mwait_timeout)\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m found:\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Always update progress to 100% when done\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m on_progress \u001b[39mand\u001b[39;00m progress_handle \u001b[39mand\u001b[39;00m progress_sent:\n",
      "File \u001b[0;32m~/miniconda3/envs/tianshou/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py:130\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_and_clear\u001b[39m(\u001b[39mself\u001b[39m, timeout: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Optional[pb\u001b[39m.\u001b[39mResult], \u001b[39mbool\u001b[39m]:\n\u001b[1;32m    129\u001b[0m     found \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout\u001b[39m=\u001b[39;49mtimeout):\n\u001b[1;32m    131\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m             found \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniconda3/envs/tianshou/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py:126\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wait\u001b[39m(\u001b[39mself\u001b[39m, timeout: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout\u001b[39m=\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/tianshou/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/tianshou/lib/python3.11/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if args.resume_path:\n",
    "    policy.load_state_dict(torch.load(args.resume_path, map_location=args.device))\n",
    "    print(\"Loaded agent from: \", args.resume_path)\n",
    "# replay buffer: `save_last_obs` and `stack_num` can be removed together\n",
    "# when you have enough RAM\n",
    "buffer = VectorReplayBuffer(\n",
    "    args.buffer_size,\n",
    "    buffer_num=len(train_envs),\n",
    "    ignore_obs_next=True,\n",
    "    save_only_last_obs=False,\n",
    "    stack_num=args.frames_stack\n",
    ")\n",
    "# collector\n",
    "train_collector = Collector(policy, train_envs, buffer, exploration_noise=True)\n",
    "test_collector = Collector(policy, test_envs, exploration_noise=True)\n",
    "\n",
    "# log\n",
    "now = datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\")\n",
    "args.algo_name = \"ppo_icm\" if args.icm_lr_scale > 0 else \"ppo\"\n",
    "log_name = os.path.join(args.task, args.algo_name, str(args.seed), now)\n",
    "log_path = os.path.join(args.logdir, log_name)\n",
    "\n",
    "# logger\n",
    "if args.logger == \"wandb\":\n",
    "    logger = WandbLogger(\n",
    "        save_interval=1,\n",
    "        name=log_name.replace(os.path.sep, \"__\"),\n",
    "        run_id=args.resume_id,\n",
    "        config=args,\n",
    "        project=args.wandb_project,\n",
    "    )\n",
    "writer = SummaryWriter(log_path)\n",
    "writer.add_text(\"args\", str(args))\n",
    "if args.logger == \"tensorboard\":\n",
    "    logger = TensorboardLogger(writer)\n",
    "else:  # wandb\n",
    "    logger.load(writer)\n",
    "\n",
    "def save_best_fn(policy):\n",
    "    torch.save(policy.state_dict(), os.path.join(log_path, \"policy.pth\"))\n",
    "\n",
    "def stop_fn(mean_rewards):\n",
    "    return mean_rewards >= 0\n",
    "\n",
    "def save_checkpoint_fn(epoch, env_step, gradient_step):\n",
    "    # see also: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "    ckpt_path = os.path.join(log_path, \"checkpoint.pth\")\n",
    "    torch.save({\"model\": policy.state_dict()}, ckpt_path)\n",
    "    return ckpt_path\n",
    "\n",
    "# watch agent's performance\n",
    "def watch():\n",
    "    print(\"Setup test envs ...\")\n",
    "    policy.eval()\n",
    "    test_envs.seed(args.seed)\n",
    "    if args.save_buffer_name:\n",
    "        print(f\"Generate buffer with size {args.buffer_size}\")\n",
    "        buffer = VectorReplayBuffer(\n",
    "            args.buffer_size,\n",
    "            buffer_num=len(test_envs),\n",
    "            ignore_obs_next=True,\n",
    "            save_only_last_obs=True,\n",
    "            stack_num=args.frames_stack,\n",
    "        )\n",
    "        collector = Collector(policy, test_envs, buffer, exploration_noise=True)\n",
    "        result = collector.collect(n_step=args.buffer_size)\n",
    "        print(f\"Save buffer into {args.save_buffer_name}\")\n",
    "        # Unfortunately, pickle will cause oom with 1M buffer size\n",
    "        buffer.save_hdf5(args.save_buffer_name)\n",
    "    else:\n",
    "        print(\"Testing agent ...\")\n",
    "        test_collector.reset()\n",
    "        result = test_collector.collect(\n",
    "            n_episode=args.test_num, render=args.render\n",
    "        )\n",
    "    rew = result[\"rews\"].mean()\n",
    "    print(f\"Mean reward (over {result['n/ep']} episodes): {rew}\")\n",
    "\n",
    "if args.watch:\n",
    "    watch()\n",
    "    exit(0)\n",
    "\n",
    "# test train_collector and start filling replay buffer\n",
    "train_collector.collect(n_step=args.batch_size * args.training_num)\n",
    "# trainer\n",
    "result = onpolicy_trainer(\n",
    "    policy,\n",
    "    train_collector,\n",
    "    test_collector,\n",
    "    args.epoch,\n",
    "    args.step_per_epoch,\n",
    "    args.repeat_per_collect,\n",
    "    args.test_num,\n",
    "    args.batch_size,\n",
    "    step_per_collect=args.step_per_collect,\n",
    "    stop_fn=stop_fn,\n",
    "    save_best_fn=save_best_fn,\n",
    "    logger=logger,\n",
    "    test_in_train=False,\n",
    "    resume_from_log=args.resume_id is not None,\n",
    "    save_checkpoint_fn=save_checkpoint_fn,\n",
    ")\n",
    "\n",
    "pprint.pprint(result)\n",
    "watch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tianshou",
   "language": "python",
   "name": "tianshou"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
