{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4255df2",
   "metadata": {},
   "source": [
    "### 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef46089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:40:14.783680Z",
     "start_time": "2023-11-22T02:40:14.780257Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/tmp-data/zhx/DriverOrderOfflineRL/tianshou')\n",
    "sys.path.append('/tmp-data/zhx/DriverOrderOfflineRL/gym')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2dde2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-13T07:27:54.476843Z",
     "start_time": "2023-11-13T07:27:54.474091Z"
    }
   },
   "source": [
    "### import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f15928a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:40:20.476468Z",
     "start_time": "2023-11-22T02:40:15.698920Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/wandb/sdk/launch/builder/build.py:11: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import h5py\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import Any, Dict, Optional, Sequence, Tuple, Union\n",
    "\n",
    "from tianshou.data import Collector, VectorReplayBuffer, ReplayBuffer\n",
    "from tianshou.policy import DiscreteCQLPolicy\n",
    "from tianshou.trainer import offline_trainer\n",
    "from tianshou.utils import TensorboardLogger, WandbLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6dacc8",
   "metadata": {},
   "source": [
    "### args config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "226e5db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:03.247065Z",
     "start_time": "2023-11-22T02:54:03.234604Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--task\", type=str, default=\"OrderFilter\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=0)\n",
    "    parser.add_argument(\"--eps-test\", type=float, default=0.001)\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.0001)\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99)\n",
    "    parser.add_argument(\"--num-quantiles\", type=int, default=32)\n",
    "    parser.add_argument(\"--n-step\", type=int, default=1)\n",
    "    parser.add_argument(\"--target-update-freq\", type=int, default=500)\n",
    "    parser.add_argument(\"--min-q-weight\", type=float, default=10.)\n",
    "    parser.add_argument(\"--epoch\", type=int, default=100)\n",
    "    parser.add_argument(\"--update-per-epoch\", type=int, default=10000)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=32)\n",
    "    parser.add_argument(\"--hidden-sizes\", type=int, nargs=\"*\", default=[512])\n",
    "    parser.add_argument(\"--test-num\", type=int, default=10)\n",
    "    parser.add_argument(\"--frames-stack\", type=int, default=1)\n",
    "    parser.add_argument(\"--scale-obs\", type=int, default=0)\n",
    "    parser.add_argument(\"--logdir\", type=str, default=\"log\")\n",
    "    parser.add_argument(\"--render\", type=float, default=0.)\n",
    "    parser.add_argument(\"--resume-path\", type=str, default='/tmp-data/zhx/DriverOrderOfflineRL/scripts/log/OrderFilter/cql/0/231121-070714/1700.pth')\n",
    "    parser.add_argument(\"--resume-id\", type=str, default=None)\n",
    "    parser.add_argument(\n",
    "        \"--logger\",\n",
    "        type=str,\n",
    "        default=\"wandb\",\n",
    "        choices=[\"tensorboard\", \"wandb\"],\n",
    "    )\n",
    "    parser.add_argument(\"--wandb-project\", type=str, default=\"offline_driver.QRDQN\")\n",
    "    parser.add_argument(\n",
    "        \"--watch\",\n",
    "        default=False,\n",
    "        action=\"store_true\",\n",
    "        help=\"watch the play of pre-trained policy only\"\n",
    "    )\n",
    "    parser.add_argument(\"--log-interval\", type=int, default=100)\n",
    "    parser.add_argument(\n",
    "        \"--load-buffer-name\", type=str, default=\"/tmp-data/yanhaoyue/workspace/RL/data/support_feature_buffer.h5\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--buffer-from-rl-unplugged\", action=\"store_true\", default=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    args = parser.parse_known_args()[0]\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86080afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:08.530291Z",
     "start_time": "2023-11-22T02:54:08.523289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(task='OrderFilter', seed=0, eps_test=0.001, lr=0.0001, gamma=0.99, num_quantiles=32, n_step=1, target_update_freq=500, min_q_weight=10.0, epoch=100, update_per_epoch=10000, batch_size=32, hidden_sizes=[512], test_num=10, frames_stack=1, scale_obs=0, logdir='log', render=0.0, resume_path='/tmp-data/zhx/DriverOrderOfflineRL/scripts/log/OrderFilter/cql/0/231121-070714/1700.pth', resume_id=None, logger='wandb', wandb_project='offline_driver.QRDQN', watch=False, log_interval=100, load_buffer_name='/tmp-data/yanhaoyue/workspace/RL/data/support_feature_buffer.h5', buffer_from_rl_unplugged=True, device='cpu')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = get_args()\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbb0df",
   "metadata": {},
   "source": [
    "### load buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71471051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:10.012307Z",
     "start_time": "2023-11-22T02:54:10.007065Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_buffer(buffer_path: str) -> ReplayBuffer:\n",
    "    with h5py.File(buffer_path, \"r\") as dataset:\n",
    "        buffer = ReplayBuffer.from_data(\n",
    "            obs=dataset[\"observations\"],\n",
    "            act=dataset[\"actions\"],\n",
    "            rew=dataset[\"rewards\"],\n",
    "            done=dataset[\"terminals\"],\n",
    "            obs_next=dataset[\"next_observations\"]\n",
    "        )\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19f559e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:13.264771Z",
     "start_time": "2023-11-22T02:54:11.157850Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp-data/zhx/DriverOrderOfflineRL/tianshou/tianshou/data/batch.py:59: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  obj_array = np.asanyarray(obj)\n"
     ]
    }
   ],
   "source": [
    "buffer = load_buffer(args.load_buffer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50801e77",
   "metadata": {},
   "source": [
    "### network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3385b4c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:13.305140Z",
     "start_time": "2023-11-22T02:54:13.279216Z"
    },
    "code_folding": [
     0,
     46
    ]
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"Reference: Human-level control through deep reinforcement learning.\n",
    "\n",
    "    For advanced usage (how to customize the network), please refer to\n",
    "    :ref:`build_the_network`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_shape: Sequence[int],\n",
    "        action_shape: Sequence[int],\n",
    "        device: Union[str, int, torch.device] = \"cpu\",\n",
    "        features_only: bool = False,\n",
    "        output_dim: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_shape, 512), nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, action_shape), nn.ReLU(inplace=True),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            self.output_dim = np.prod(self.net(torch.zeros(1, state_shape)).shape[1:])\n",
    "        if not features_only:\n",
    "            self.net = nn.Sequential(\n",
    "                self.net, nn.Linear(self.output_dim, 512), nn.ReLU(inplace=True),\n",
    "                nn.Linear(512, np.prod(action_shape))\n",
    "            )\n",
    "            self.output_dim = np.prod(action_shape)\n",
    "        elif output_dim is not None:\n",
    "            self.net = nn.Sequential(\n",
    "                self.net, nn.Linear(self.output_dim, output_dim),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            self.output_dim = output_dim\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        obs: Union[np.ndarray, torch.Tensor],\n",
    "        state: Optional[Any] = None,\n",
    "        info: Dict[str, Any] = {},\n",
    "    ) -> Tuple[torch.Tensor, Any]:\n",
    "        r\"\"\"Mapping: s -> Q(s, \\*).\"\"\"\n",
    "        obs = torch.as_tensor(obs, device=self.device, dtype=torch.float32)\n",
    "        return self.net(obs), state\n",
    "class QRDQN(DQN):\n",
    "    \"\"\"Reference: Distributional Reinforcement Learning with Quantile \\\n",
    "    Regression.\n",
    "\n",
    "    For advanced usage (how to customize the network), please refer to\n",
    "    :ref:`build_the_network`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_shape: Sequence[int],\n",
    "        action_shape: Sequence[int],\n",
    "        num_quantiles: int = 32,\n",
    "        device: Union[str, int, torch.device] = \"cpu\",\n",
    "    ) -> None:\n",
    "        self.action_num = np.prod(action_shape)\n",
    "        super().__init__(state_shape, self.action_num * num_quantiles, device)\n",
    "        self.num_quantiles = num_quantiles\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        obs: Union[np.ndarray, torch.Tensor],\n",
    "        state: Optional[Any] = None,\n",
    "        info: Dict[str, Any] = {},\n",
    "    ) -> Tuple[torch.Tensor, Any]:\n",
    "        r\"\"\"Mapping: x -> Z(x, \\*).\"\"\"\n",
    "        obs, state = super().forward(obs)\n",
    "        obs = obs.view(-1, self.action_num, self.num_quantiles)\n",
    "        return obs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f945dc3",
   "metadata": {},
   "source": [
    "### seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f962d3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:13.321947Z",
     "start_time": "2023-11-22T02:54:13.316032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f923bed1410>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbf036",
   "metadata": {},
   "source": [
    "### buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1f85a0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:13.628494Z",
     "start_time": "2023-11-22T02:54:13.625609Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# buffer_data = pd.read_csv('/tmp-data/yanhaoyue/workspace/RL/data/support_feature_buffer.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0232e163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:13.895149Z",
     "start_time": "2023-11-22T02:54:13.892203Z"
    }
   },
   "outputs": [],
   "source": [
    "# import ast\n",
    "# s = buffer_data['s'].apply(ast.literal_eval).values\n",
    "# a = buffer_data['a'].values\n",
    "# r = buffer_data['r'].values\n",
    "# s_ = buffer_data['s_'].apply(ast.literal_eval).values\n",
    "# d = buffer_data['d'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2dec3894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:14.240789Z",
     "start_time": "2023-11-22T02:54:14.237795Z"
    }
   },
   "outputs": [],
   "source": [
    "# s = np.array([np.array(item) for item in s])\n",
    "# s_ = np.array([np.array(item) for item in s_])\n",
    "# d = np.bool_(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ccb2f003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:14.396855Z",
     "start_time": "2023-11-22T02:54:14.392841Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# with h5py.File('/tmp-data/yanhaoyue/workspace/RL/data/support_feature_buffer.h5', 'w') as f:\n",
    "#     f.create_dataset('observations', data=s)\n",
    "#     f.create_dataset('actions', data=a)\n",
    "#     f.create_dataset('rewards', data=r)\n",
    "#     f.create_dataset('terminals', data=d)\n",
    "#     f.create_dataset('next_observations', data=s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7a43b99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:16.199434Z",
     "start_time": "2023-11-22T02:54:14.542128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replay buffer size: 837295\n"
     ]
    }
   ],
   "source": [
    "# buffer\n",
    "if args.buffer_from_rl_unplugged:\n",
    "    buffer = load_buffer(args.load_buffer_name)\n",
    "else:\n",
    "    assert os.path.exists(args.load_buffer_name), \\\n",
    "        \"Please run atari_dqn.py first to get expert's data buffer.\"\n",
    "    if args.load_buffer_name.endswith(\".pkl\"):\n",
    "        buffer = pickle.load(open(args.load_buffer_name, \"rb\"))\n",
    "    elif args.load_buffer_name.endswith(\".hdf5\"):\n",
    "        buffer = VectorReplayBuffer.load_hdf5(args.load_buffer_name)\n",
    "    else:\n",
    "        print(f\"Unknown buffer format: {args.load_buffer_name}\")\n",
    "        exit(0)\n",
    "print(\"Replay buffer size:\", len(buffer), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a45164",
   "metadata": {},
   "source": [
    "### env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ecd62ca8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:16.214756Z",
     "start_time": "2023-11-22T02:54:16.210444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations shape: 109\n",
      "Actions shape: 6\n"
     ]
    }
   ],
   "source": [
    "args.state_shape = buffer.obs.shape[1]\n",
    "args.action_shape = 6 # 0， 1， 2， 3， 4， 5分位数\n",
    "print(\"Observations shape:\", args.state_shape)\n",
    "print(\"Actions shape:\", args.action_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd813f38",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8fcd2563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:16.299143Z",
     "start_time": "2023-11-22T02:54:16.280225Z"
    }
   },
   "outputs": [],
   "source": [
    "# model\n",
    "net = QRDQN(args.state_shape, args.action_shape, args.num_quantiles, args.device)\n",
    "optim = torch.optim.Adam(net.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062901f",
   "metadata": {},
   "source": [
    "### policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2a7b81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:16.949626Z",
     "start_time": "2023-11-22T02:54:16.856002Z"
    }
   },
   "outputs": [],
   "source": [
    "# define policy\n",
    "policy = DiscreteCQLPolicy(\n",
    "    net,\n",
    "    optim,\n",
    "    args.gamma,\n",
    "    args.num_quantiles,\n",
    "    args.n_step,\n",
    "    args.target_update_freq,\n",
    "    min_q_weight=args.min_q_weight,\n",
    ").to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e3064",
   "metadata": {},
   "source": [
    "### load policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ea30b2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T02:54:18.642165Z",
     "start_time": "2023-11-22T02:54:18.467395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded agent from:  /tmp-data/zhx/DriverOrderOfflineRL/scripts/log/OrderFilter/cql/0/231121-070714/1700.pth\n"
     ]
    }
   ],
   "source": [
    "# load a previous policy\n",
    "if args.resume_path:\n",
    "    policy.load_state_dict(torch.load(args.resume_path, map_location=args.device)['model'])\n",
    "    print(\"Loaded agent from: \", args.resume_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "27db5430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:02:05.893298Z",
     "start_time": "2023-11-22T03:02:05.837105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.model(torch.from_numpy(buffer[0]['obs']).view(1, -1))[0].sum(2).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eee2d386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:27:50.146159Z",
     "start_time": "2023-11-22T03:27:34.095114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 1000 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1001 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1002 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1003 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1004 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1005 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1006 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1007 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1008 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1009 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1010 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1011 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1012 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1013 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1014 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1015 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1016 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1017 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1018 模型选的动作 5 想要学习的动作 2.0\n",
      "轮次 1019 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1020 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1021 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1022 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1023 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1024 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1025 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1026 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1027 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1028 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1029 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1030 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1031 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1032 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1033 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1034 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1035 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1036 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1037 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1038 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1039 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1040 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1041 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1042 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1043 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1044 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1045 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1046 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1047 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1048 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1049 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1050 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1051 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1052 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1053 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1054 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1055 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1056 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1057 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1058 模型选的动作 5 想要学习的动作 2.0\n",
      "轮次 1059 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1060 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1061 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1062 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1063 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1064 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1065 模型选的动作 5 想要学习的动作 2.0\n",
      "轮次 1066 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1067 模型选的动作 5 想要学习的动作 2.0\n",
      "轮次 1068 模型选的动作 5 想要学习的动作 2.0\n",
      "轮次 1069 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1070 模型选的动作 5 想要学习的动作 2.0\n",
      "轮次 1071 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1072 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1073 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1074 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1075 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1076 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1077 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1078 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1079 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1080 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1081 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1082 模型选的动作 5 想要学习的动作 2.0\n",
      "轮次 1083 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1084 模型选的动作 5 想要学习的动作 4.0\n",
      "轮次 1085 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1086 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1087 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1088 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1089 模型选的动作 5 想要学习的动作 2.0\n",
      "轮次 1090 模型选的动作 5 想要学习的动作 5.0\n",
      "轮次 1091 模型选的动作 5 想要学习的动作 2.0\n",
      "轮次 1092 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1093 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1094 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1095 模型选的动作 5 想要学习的动作 1.0\n",
      "轮次 1096 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1097 模型选的动作 5 想要学习的动作 3.0\n",
      "轮次 1098 模型选的动作 5 想要学习的动作 0.0\n",
      "轮次 1099 模型选的动作 5 想要学习的动作 5.0\n",
      "error 1.98\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "for idx in range(1000, 1100):\n",
    "    error += abs(policy.model(torch.from_numpy(buffer[idx]['obs']).view(1, -1))[0][0].sum(1).argmax().item() - buffer[idx]['act'])\n",
    "    print('轮次', idx, \n",
    "          '模型选的动作',\n",
    "          policy.model(torch.from_numpy(buffer[idx]['obs']).view(1, -1))[0][0].sum(1).argmax().item(), \n",
    "          '想要学习的动作',\n",
    "          buffer[idx]['act'])\n",
    "print('error', error / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee5df8",
   "metadata": {},
   "source": [
    "### logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9bf078a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:05:02.946708Z",
     "start_time": "2023-11-21T07:04:59.060994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhongxi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n",
      "/tmp-data/conda/anaconda3/envs/rl_test/lib/python3.9/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp-data/zhx/DriverOrderOfflineRL/scripts/wandb/run-20231121_070500-h6vyykaf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hongxi/offline_driver.QRDQN/runs/h6vyykaf' target=\"_blank\">OrderFilter__cql__0__231121-070459</a></strong> to <a href='https://wandb.ai/hongxi/offline_driver.QRDQN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hongxi/offline_driver.QRDQN' target=\"_blank\">https://wandb.ai/hongxi/offline_driver.QRDQN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hongxi/offline_driver.QRDQN/runs/h6vyykaf' target=\"_blank\">https://wandb.ai/hongxi/offline_driver.QRDQN/runs/h6vyykaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log\n",
    "now = datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\")\n",
    "args.algo_name = \"cql\"\n",
    "log_name = os.path.join(args.task, args.algo_name, str(args.seed), now)\n",
    "log_path = os.path.join(args.logdir, log_name)\n",
    "\n",
    "# logger\n",
    "if args.logger == \"wandb\":\n",
    "    logger = WandbLogger(\n",
    "        save_interval=1,\n",
    "        name=log_name.replace(os.path.sep, \"__\"),\n",
    "        run_id=args.resume_id,\n",
    "        config=args,\n",
    "        project=args.wandb_project,\n",
    "    )\n",
    "writer = SummaryWriter(log_path)\n",
    "writer.add_text(\"args\", str(args))\n",
    "if args.logger == \"tensorboard\":\n",
    "    logger = TensorboardLogger(writer)\n",
    "else:  # wandb\n",
    "    logger.load(writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a0d3c",
   "metadata": {},
   "source": [
    "### help function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "963e8c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T07:05:11.365042Z",
     "start_time": "2023-11-21T07:05:11.357212Z"
    },
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "def save_best_fn(policy):\n",
    "    torch.save(policy.state_dict(), os.path.join(log_path, \"policy.pth\"))\n",
    "\n",
    "def stop_fn(mean_rewards):\n",
    "    return False\n",
    "\n",
    "# watch agent's performance\n",
    "def watch():\n",
    "    print(\"Setup test envs ...\")\n",
    "    policy.eval()\n",
    "    policy.set_eps(args.eps_test)\n",
    "    test_envs.seed(args.seed)\n",
    "    print(\"Testing agent ...\")\n",
    "    test_collector.reset()\n",
    "    result = test_collector.collect(n_episode=args.test_num, render=args.render)\n",
    "    pprint.pprint(result)\n",
    "    rew = result[\"rews\"].mean()\n",
    "    print(f'Mean reward (over {result[\"n/ep\"]} episodes): {rew}')\n",
    "    \n",
    "def save_checkpoint_fn(epoch, env_step, gradient_step):\n",
    "    # see also: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "    ckpt_path = os.path.join(log_path, str(epoch) + \".pth\")\n",
    "    torch.save({\"model\": policy.state_dict()}, ckpt_path)\n",
    "    return ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c8374b",
   "metadata": {},
   "source": [
    "### train core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3b37f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T07:05:13.036Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if args.watch:\n",
    "    watch()\n",
    "    exit(0)\n",
    "import wandb\n",
    "for epoch in range(1, args.epoch + 1):\n",
    "    wandb.log(policy.update(0, buffer, batch_size=args.batch_size, repeat=1))\n",
    "    save_checkpoint_fn(epoch, 0, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_test",
   "language": "python",
   "name": "rl_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
